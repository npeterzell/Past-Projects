{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Notebook\n",
    "**Nicholas Peterzell**<br>\n",
    "**A15278235**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.metrics import classification_report\n",
    "from statistics import mean\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the datasets\n",
    "bean_df = pd.read_excel('Dry_Bean_Dataset.xlsx')\n",
    "bike_df = pd.read_csv('bike_hour.csv')\n",
    "shoppers_df = pd.read_csv('online_shoppers_intention.csv')\n",
    "stars_df = pd.read_csv('HTRU_2.csv', names=['Mean (integrated profile)',\n",
    "                                            'Standard deviation (integrated profile)',\n",
    "                                            'Excess kurtosis (integrated profile)',\n",
    "                                            'Skewness (integrated profile)',\n",
    "                                            'Mean (DM-SNR curve)',\n",
    "                                            'Standard deviation (DM-SNR curve)',\n",
    "                                            'Excess kurtosis (DM-SNR curve)',\n",
    "                                            'Skewness (DM-SNR curve)',\n",
    "                                            'Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28395</td>\n",
       "      <td>610.291</td>\n",
       "      <td>208.178117</td>\n",
       "      <td>173.888747</td>\n",
       "      <td>1.197191</td>\n",
       "      <td>0.549812</td>\n",
       "      <td>28715</td>\n",
       "      <td>190.141097</td>\n",
       "      <td>0.763923</td>\n",
       "      <td>0.988856</td>\n",
       "      <td>0.958027</td>\n",
       "      <td>0.913358</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.834222</td>\n",
       "      <td>0.998724</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28734</td>\n",
       "      <td>638.018</td>\n",
       "      <td>200.524796</td>\n",
       "      <td>182.734419</td>\n",
       "      <td>1.097356</td>\n",
       "      <td>0.411785</td>\n",
       "      <td>29172</td>\n",
       "      <td>191.272750</td>\n",
       "      <td>0.783968</td>\n",
       "      <td>0.984986</td>\n",
       "      <td>0.887034</td>\n",
       "      <td>0.953861</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29380</td>\n",
       "      <td>624.110</td>\n",
       "      <td>212.826130</td>\n",
       "      <td>175.931143</td>\n",
       "      <td>1.209713</td>\n",
       "      <td>0.562727</td>\n",
       "      <td>29690</td>\n",
       "      <td>193.410904</td>\n",
       "      <td>0.778113</td>\n",
       "      <td>0.989559</td>\n",
       "      <td>0.947849</td>\n",
       "      <td>0.908774</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30008</td>\n",
       "      <td>645.884</td>\n",
       "      <td>210.557999</td>\n",
       "      <td>182.516516</td>\n",
       "      <td>1.153638</td>\n",
       "      <td>0.498616</td>\n",
       "      <td>30724</td>\n",
       "      <td>195.467062</td>\n",
       "      <td>0.782681</td>\n",
       "      <td>0.976696</td>\n",
       "      <td>0.903936</td>\n",
       "      <td>0.928329</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.861794</td>\n",
       "      <td>0.994199</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30140</td>\n",
       "      <td>620.134</td>\n",
       "      <td>201.847882</td>\n",
       "      <td>190.279279</td>\n",
       "      <td>1.060798</td>\n",
       "      <td>0.333680</td>\n",
       "      <td>30417</td>\n",
       "      <td>195.896503</td>\n",
       "      <td>0.773098</td>\n",
       "      <td>0.990893</td>\n",
       "      <td>0.984877</td>\n",
       "      <td>0.970516</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13606</th>\n",
       "      <td>42097</td>\n",
       "      <td>759.696</td>\n",
       "      <td>288.721612</td>\n",
       "      <td>185.944705</td>\n",
       "      <td>1.552728</td>\n",
       "      <td>0.765002</td>\n",
       "      <td>42508</td>\n",
       "      <td>231.515799</td>\n",
       "      <td>0.714574</td>\n",
       "      <td>0.990331</td>\n",
       "      <td>0.916603</td>\n",
       "      <td>0.801865</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.642988</td>\n",
       "      <td>0.998385</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13607</th>\n",
       "      <td>42101</td>\n",
       "      <td>757.499</td>\n",
       "      <td>281.576392</td>\n",
       "      <td>190.713136</td>\n",
       "      <td>1.476439</td>\n",
       "      <td>0.735702</td>\n",
       "      <td>42494</td>\n",
       "      <td>231.526798</td>\n",
       "      <td>0.799943</td>\n",
       "      <td>0.990752</td>\n",
       "      <td>0.922015</td>\n",
       "      <td>0.822252</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.676099</td>\n",
       "      <td>0.998219</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13608</th>\n",
       "      <td>42139</td>\n",
       "      <td>759.321</td>\n",
       "      <td>281.539928</td>\n",
       "      <td>191.187979</td>\n",
       "      <td>1.472582</td>\n",
       "      <td>0.734065</td>\n",
       "      <td>42569</td>\n",
       "      <td>231.631261</td>\n",
       "      <td>0.729932</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.918424</td>\n",
       "      <td>0.822730</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.676884</td>\n",
       "      <td>0.996767</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13609</th>\n",
       "      <td>42147</td>\n",
       "      <td>763.779</td>\n",
       "      <td>283.382636</td>\n",
       "      <td>190.275731</td>\n",
       "      <td>1.489326</td>\n",
       "      <td>0.741055</td>\n",
       "      <td>42667</td>\n",
       "      <td>231.653248</td>\n",
       "      <td>0.705389</td>\n",
       "      <td>0.987813</td>\n",
       "      <td>0.907906</td>\n",
       "      <td>0.817457</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.668237</td>\n",
       "      <td>0.995222</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13610</th>\n",
       "      <td>42159</td>\n",
       "      <td>772.237</td>\n",
       "      <td>295.142741</td>\n",
       "      <td>182.204716</td>\n",
       "      <td>1.619841</td>\n",
       "      <td>0.786693</td>\n",
       "      <td>42600</td>\n",
       "      <td>231.686223</td>\n",
       "      <td>0.788962</td>\n",
       "      <td>0.989648</td>\n",
       "      <td>0.888380</td>\n",
       "      <td>0.784997</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.616221</td>\n",
       "      <td>0.998180</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13611 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "0      28395    610.291       208.178117       173.888747      1.197191   \n",
       "1      28734    638.018       200.524796       182.734419      1.097356   \n",
       "2      29380    624.110       212.826130       175.931143      1.209713   \n",
       "3      30008    645.884       210.557999       182.516516      1.153638   \n",
       "4      30140    620.134       201.847882       190.279279      1.060798   \n",
       "...      ...        ...              ...              ...           ...   \n",
       "13606  42097    759.696       288.721612       185.944705      1.552728   \n",
       "13607  42101    757.499       281.576392       190.713136      1.476439   \n",
       "13608  42139    759.321       281.539928       191.187979      1.472582   \n",
       "13609  42147    763.779       283.382636       190.275731      1.489326   \n",
       "13610  42159    772.237       295.142741       182.204716      1.619841   \n",
       "\n",
       "       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
       "0          0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
       "1          0.411785       29172     191.272750  0.783968  0.984986   0.887034   \n",
       "2          0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
       "3          0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
       "4          0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
       "...             ...         ...            ...       ...       ...        ...   \n",
       "13606      0.765002       42508     231.515799  0.714574  0.990331   0.916603   \n",
       "13607      0.735702       42494     231.526798  0.799943  0.990752   0.922015   \n",
       "13608      0.734065       42569     231.631261  0.729932  0.989899   0.918424   \n",
       "13609      0.741055       42667     231.653248  0.705389  0.987813   0.907906   \n",
       "13610      0.786693       42600     231.686223  0.788962  0.989648   0.888380   \n",
       "\n",
       "       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n",
       "0         0.913358      0.007332      0.003147      0.834222      0.998724   \n",
       "1         0.953861      0.006979      0.003564      0.909851      0.998430   \n",
       "2         0.908774      0.007244      0.003048      0.825871      0.999066   \n",
       "3         0.928329      0.007017      0.003215      0.861794      0.994199   \n",
       "4         0.970516      0.006697      0.003665      0.941900      0.999166   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "13606     0.801865      0.006858      0.001749      0.642988      0.998385   \n",
       "13607     0.822252      0.006688      0.001886      0.676099      0.998219   \n",
       "13608     0.822730      0.006681      0.001888      0.676884      0.996767   \n",
       "13609     0.817457      0.006724      0.001852      0.668237      0.995222   \n",
       "13610     0.784997      0.007001      0.001640      0.616221      0.998180   \n",
       "\n",
       "          Class  \n",
       "0         SEKER  \n",
       "1         SEKER  \n",
       "2         SEKER  \n",
       "3         SEKER  \n",
       "4         SEKER  \n",
       "...         ...  \n",
       "13606  DERMASON  \n",
       "13607  DERMASON  \n",
       "13608  DERMASON  \n",
       "13609  DERMASON  \n",
       "13610  DERMASON  \n",
       "\n",
       "[13611 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the datasets\n",
    "bean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>17375</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>11</td>\n",
       "      <td>108</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>17376</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>17377</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>17378</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>17379</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       instant      dteday  season  yr  mnth  hr  holiday  weekday  \\\n",
       "0            1  2011-01-01       1   0     1   0        0        6   \n",
       "1            2  2011-01-01       1   0     1   1        0        6   \n",
       "2            3  2011-01-01       1   0     1   2        0        6   \n",
       "3            4  2011-01-01       1   0     1   3        0        6   \n",
       "4            5  2011-01-01       1   0     1   4        0        6   \n",
       "...        ...         ...     ...  ..   ...  ..      ...      ...   \n",
       "17374    17375  2012-12-31       1   1    12  19        0        1   \n",
       "17375    17376  2012-12-31       1   1    12  20        0        1   \n",
       "17376    17377  2012-12-31       1   1    12  21        0        1   \n",
       "17377    17378  2012-12-31       1   1    12  22        0        1   \n",
       "17378    17379  2012-12-31       1   1    12  23        0        1   \n",
       "\n",
       "       workingday  weathersit  temp   atemp   hum  windspeed  casual  \\\n",
       "0               0           1  0.24  0.2879  0.81     0.0000       3   \n",
       "1               0           1  0.22  0.2727  0.80     0.0000       8   \n",
       "2               0           1  0.22  0.2727  0.80     0.0000       5   \n",
       "3               0           1  0.24  0.2879  0.75     0.0000       3   \n",
       "4               0           1  0.24  0.2879  0.75     0.0000       0   \n",
       "...           ...         ...   ...     ...   ...        ...     ...   \n",
       "17374           1           2  0.26  0.2576  0.60     0.1642      11   \n",
       "17375           1           2  0.26  0.2576  0.60     0.1642       8   \n",
       "17376           1           1  0.26  0.2576  0.60     0.1642       7   \n",
       "17377           1           1  0.26  0.2727  0.56     0.1343      13   \n",
       "17378           1           1  0.26  0.2727  0.65     0.1343      12   \n",
       "\n",
       "       registered  cnt  \n",
       "0              13   16  \n",
       "1              32   40  \n",
       "2              27   32  \n",
       "3              10   13  \n",
       "4               1    1  \n",
       "...           ...  ...  \n",
       "17374         108  119  \n",
       "17375          81   89  \n",
       "17376          83   90  \n",
       "17377          48   61  \n",
       "17378          37   49  \n",
       "\n",
       "[17379 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12325</th>\n",
       "      <td>3</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53</td>\n",
       "      <td>1783.791667</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.029031</td>\n",
       "      <td>12.241717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dec</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12326</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>465.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12327</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>184.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>4</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12329</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>New_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12330 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Administrative  Administrative_Duration  Informational  \\\n",
       "0                   0                      0.0              0   \n",
       "1                   0                      0.0              0   \n",
       "2                   0                      0.0              0   \n",
       "3                   0                      0.0              0   \n",
       "4                   0                      0.0              0   \n",
       "...               ...                      ...            ...   \n",
       "12325               3                    145.0              0   \n",
       "12326               0                      0.0              0   \n",
       "12327               0                      0.0              0   \n",
       "12328               4                     75.0              0   \n",
       "12329               0                      0.0              0   \n",
       "\n",
       "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                         0.0               1                 0.000000   \n",
       "1                         0.0               2                64.000000   \n",
       "2                         0.0               1                 0.000000   \n",
       "3                         0.0               2                 2.666667   \n",
       "4                         0.0              10               627.500000   \n",
       "...                       ...             ...                      ...   \n",
       "12325                     0.0              53              1783.791667   \n",
       "12326                     0.0               5               465.750000   \n",
       "12327                     0.0               6               184.250000   \n",
       "12328                     0.0              15               346.000000   \n",
       "12329                     0.0               3                21.250000   \n",
       "\n",
       "       BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.200000   0.200000    0.000000         0.0   Feb                 1   \n",
       "1         0.000000   0.100000    0.000000         0.0   Feb                 2   \n",
       "2         0.200000   0.200000    0.000000         0.0   Feb                 4   \n",
       "3         0.050000   0.140000    0.000000         0.0   Feb                 3   \n",
       "4         0.020000   0.050000    0.000000         0.0   Feb                 3   \n",
       "...            ...        ...         ...         ...   ...               ...   \n",
       "12325     0.007143   0.029031   12.241717         0.0   Dec                 4   \n",
       "12326     0.000000   0.021333    0.000000         0.0   Nov                 3   \n",
       "12327     0.083333   0.086667    0.000000         0.0   Nov                 3   \n",
       "12328     0.000000   0.021053    0.000000         0.0   Nov                 2   \n",
       "12329     0.000000   0.066667    0.000000         0.0   Nov                 3   \n",
       "\n",
       "       Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0            1       1            1  Returning_Visitor    False    False  \n",
       "1            2       1            2  Returning_Visitor    False    False  \n",
       "2            1       9            3  Returning_Visitor    False    False  \n",
       "3            2       2            4  Returning_Visitor    False    False  \n",
       "4            3       1            4  Returning_Visitor     True    False  \n",
       "...        ...     ...          ...                ...      ...      ...  \n",
       "12325        6       1            1  Returning_Visitor     True    False  \n",
       "12326        2       1            8  Returning_Visitor     True    False  \n",
       "12327        2       1           13  Returning_Visitor     True    False  \n",
       "12328        2       3           11  Returning_Visitor    False    False  \n",
       "12329        2       1            2        New_Visitor     True    False  \n",
       "\n",
       "[12330 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoppers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean (integrated profile)</th>\n",
       "      <th>Standard deviation (integrated profile)</th>\n",
       "      <th>Excess kurtosis (integrated profile)</th>\n",
       "      <th>Skewness (integrated profile)</th>\n",
       "      <th>Mean (DM-SNR curve)</th>\n",
       "      <th>Standard deviation (DM-SNR curve)</th>\n",
       "      <th>Excess kurtosis (DM-SNR curve)</th>\n",
       "      <th>Skewness (DM-SNR curve)</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.562500</td>\n",
       "      <td>55.683782</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-0.699648</td>\n",
       "      <td>3.199833</td>\n",
       "      <td>19.110426</td>\n",
       "      <td>7.975532</td>\n",
       "      <td>74.242225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.726562</td>\n",
       "      <td>40.672225</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>1.123492</td>\n",
       "      <td>1.178930</td>\n",
       "      <td>11.468720</td>\n",
       "      <td>14.269573</td>\n",
       "      <td>252.567306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17893</th>\n",
       "      <td>136.429688</td>\n",
       "      <td>59.847421</td>\n",
       "      <td>-0.187846</td>\n",
       "      <td>-0.738123</td>\n",
       "      <td>1.296823</td>\n",
       "      <td>12.166062</td>\n",
       "      <td>15.450260</td>\n",
       "      <td>285.931022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17894</th>\n",
       "      <td>122.554688</td>\n",
       "      <td>49.485605</td>\n",
       "      <td>0.127978</td>\n",
       "      <td>0.323061</td>\n",
       "      <td>16.409699</td>\n",
       "      <td>44.626893</td>\n",
       "      <td>2.945244</td>\n",
       "      <td>8.297092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17895</th>\n",
       "      <td>119.335938</td>\n",
       "      <td>59.935939</td>\n",
       "      <td>0.159363</td>\n",
       "      <td>-0.743025</td>\n",
       "      <td>21.430602</td>\n",
       "      <td>58.872000</td>\n",
       "      <td>2.499517</td>\n",
       "      <td>4.595173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17896</th>\n",
       "      <td>114.507812</td>\n",
       "      <td>53.902400</td>\n",
       "      <td>0.201161</td>\n",
       "      <td>-0.024789</td>\n",
       "      <td>1.946488</td>\n",
       "      <td>13.381731</td>\n",
       "      <td>10.007967</td>\n",
       "      <td>134.238910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17897</th>\n",
       "      <td>57.062500</td>\n",
       "      <td>85.797340</td>\n",
       "      <td>1.406391</td>\n",
       "      <td>0.089520</td>\n",
       "      <td>188.306020</td>\n",
       "      <td>64.712562</td>\n",
       "      <td>-1.597527</td>\n",
       "      <td>1.429475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17898 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mean (integrated profile)  Standard deviation (integrated profile)  \\\n",
       "0                     140.562500                                55.683782   \n",
       "1                     102.507812                                58.882430   \n",
       "2                     103.015625                                39.341649   \n",
       "3                     136.750000                                57.178449   \n",
       "4                      88.726562                                40.672225   \n",
       "...                          ...                                      ...   \n",
       "17893                 136.429688                                59.847421   \n",
       "17894                 122.554688                                49.485605   \n",
       "17895                 119.335938                                59.935939   \n",
       "17896                 114.507812                                53.902400   \n",
       "17897                  57.062500                                85.797340   \n",
       "\n",
       "       Excess kurtosis (integrated profile)  Skewness (integrated profile)  \\\n",
       "0                                 -0.234571                      -0.699648   \n",
       "1                                  0.465318                      -0.515088   \n",
       "2                                  0.323328                       1.051164   \n",
       "3                                 -0.068415                      -0.636238   \n",
       "4                                  0.600866                       1.123492   \n",
       "...                                     ...                            ...   \n",
       "17893                             -0.187846                      -0.738123   \n",
       "17894                              0.127978                       0.323061   \n",
       "17895                              0.159363                      -0.743025   \n",
       "17896                              0.201161                      -0.024789   \n",
       "17897                              1.406391                       0.089520   \n",
       "\n",
       "       Mean (DM-SNR curve)  Standard deviation (DM-SNR curve)  \\\n",
       "0                 3.199833                          19.110426   \n",
       "1                 1.677258                          14.860146   \n",
       "2                 3.121237                          21.744669   \n",
       "3                 3.642977                          20.959280   \n",
       "4                 1.178930                          11.468720   \n",
       "...                    ...                                ...   \n",
       "17893             1.296823                          12.166062   \n",
       "17894            16.409699                          44.626893   \n",
       "17895            21.430602                          58.872000   \n",
       "17896             1.946488                          13.381731   \n",
       "17897           188.306020                          64.712562   \n",
       "\n",
       "       Excess kurtosis (DM-SNR curve)  Skewness (DM-SNR curve)  Class  \n",
       "0                            7.975532                74.242225      0  \n",
       "1                           10.576487               127.393580      0  \n",
       "2                            7.735822                63.171909      0  \n",
       "3                            6.896499                53.593661      0  \n",
       "4                           14.269573               252.567306      0  \n",
       "...                               ...                      ...    ...  \n",
       "17893                       15.450260               285.931022      0  \n",
       "17894                        2.945244                 8.297092      0  \n",
       "17895                        2.499517                 4.595173      0  \n",
       "17896                       10.007967               134.238910      0  \n",
       "17897                       -1.597527                 1.429475      0  \n",
       "\n",
       "[17898 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# bean_df: Changing the labels column (Class) to a binary column with 1 for SEKER class\n",
    "# and 0 otherwise, and isolating the labels column\n",
    "\n",
    "bean_df['Class'] = bean_df['Class'].mask(bean_df['Class'] != 'SEKER', 0.0)\n",
    "bean_df['Class'] = bean_df['Class'].mask(bean_df['Class']\n",
    "                 == 'SEKER', 1.0).astype(float)\n",
    "bean_df_y = bean_df['Class']\n",
    "bean_df = bean_df.drop(['Class'], axis=1)\n",
    "\n",
    "# bike_df: Isolating the labels column (workingday) in bike_df, \n",
    "# and dropping the instant column since it is just a repeat \n",
    "# of the index column and the dteday column since it is represented \n",
    "# in other columns in numeric form\n",
    "bike_df_y = bike_df['workingday']\n",
    "bike_df = bike_df.drop(['workingday'], axis=1)\n",
    "bike_df = bike_df.drop(['instant', 'dteday'], axis=1)\n",
    "\n",
    "# shoppers_df: Turning the Month column into numerical data, making the VisitorType,\n",
    "# Weekend, and Revenue columns 0 and 1 instead of True and False, and isolating\n",
    "# the labels column\n",
    "shoppers_df['Month'] = shoppers_df['Month'].replace(['Feb', 'Mar', 'May', 'June',\n",
    "                                                     'Jul', 'Aug', 'Sep', 'Oct',\n",
    "                                                     'Nov', 'Dec'], [2, 3, 5, 6, \n",
    "                                                      7, 8, 9, 10, 11, 12])\n",
    "shoppers_df['VisitorType'] = shoppers_df['VisitorType'].mask(shoppers_df['VisitorType']\n",
    "                           != 'New_Visitor', 0.0)\n",
    "shoppers_df['VisitorType'] = shoppers_df['VisitorType'].mask(shoppers_df['VisitorType']\n",
    "                           == 'New_Visitor', 1.0).astype(float)\n",
    "shoppers_df['Weekend'] = shoppers_df['Weekend'].astype(int)\n",
    "shoppers_df['Revenue'] = shoppers_df['Revenue'].astype(int)\n",
    "shoppers_df_y = shoppers_df['VisitorType']\n",
    "shoppers_df = shoppers_df.drop(['VisitorType'], axis=1)\n",
    "\n",
    "# stars_df: Isolating the labels column in stars_df\n",
    "stars_df_y = stars_df['Class']\n",
    "stars_df = stars_df.drop(['Class'], axis=1)\n",
    "\n",
    "# All datsets: using StandardScaler() on columns without binary data\n",
    "bean_scale_cols = ['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength',\n",
    "                   'AspectRation', 'Eccentricity', 'ConvexArea', \n",
    "                   'EquivDiameter', 'Extent', 'Solidity', 'roundness', 'Compactness',\n",
    "                   'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', 'ShapeFactor4']\n",
    "bean_transformer = ColumnTransformer([('scaler', StandardScaler(), bean_scale_cols)],\n",
    "                                       remainder='passthrough')\n",
    "bean_df = bean_transformer.fit_transform(bean_df)\n",
    "\n",
    "bike_scale_cols = ['season', 'mnth', 'hr', 'weathersit', 'temp', 'atemp',\n",
    "                   'hum', 'windspeed', 'casual', 'registered', 'cnt']\n",
    "bike_transformer = ColumnTransformer([('scaler', StandardScaler(), bike_scale_cols)],\n",
    "                                       remainder='passthrough')\n",
    "bike_df = bike_transformer.fit_transform(bike_df)\n",
    "\n",
    "shoppers_scale_cols = ['Administrative', 'Administrative_Duration', 'Informational',\n",
    "                       'Informational_Duration', 'ProductRelated', \n",
    "                       'ProductRelated_Duration', 'BounceRates', 'ExitRates',\n",
    "                       'SpecialDay', 'Month', 'OperatingSystems', 'Browser', \n",
    "                       'Region', 'TrafficType']\n",
    "shoppers_transformer = ColumnTransformer([('scaler', StandardScaler(),\n",
    "                                           shoppers_scale_cols)], \n",
    "                                           remainder='passthrough')\n",
    "shoppers_df = shoppers_transformer.fit_transform(shoppers_df)\n",
    "\n",
    "stars_scale_cols = ['Mean (integrated profile)',\n",
    "                    'Standard deviation (integrated profile)',\n",
    "                    'Excess kurtosis (integrated profile)',\n",
    "                    'Skewness (integrated profile)', 'Mean (DM-SNR curve)',\n",
    "                    'Standard deviation (DM-SNR curve)',\n",
    "                    'Excess kurtosis (DM-SNR curve)', 'Skewness (DM-SNR curve)']\n",
    "stars_transformer = ColumnTransformer([('scaler', StandardScaler(), stars_scale_cols)],\n",
    "                                      remainder='passthrough')\n",
    "stars_df = stars_transformer.fit_transform(stars_df)\n",
    "\n",
    "data = [[bean_df, bean_df_y], [bike_df, bike_df_y],\n",
    "        [shoppers_df, shoppers_df_y], [stars_df, stars_df_y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent positive in the bean dataset is:\n",
      " 15%\n",
      "Percent positive in the bike dataset is:\n",
      " 68%\n",
      "Percent positive in the shoppers dataset is:\n",
      " 14%\n",
      "Percent positive in the stars dataset is:\n",
      " 9%\n"
     ]
    }
   ],
   "source": [
    "# Finding % positive on the datasets\n",
    "# Method of turning decimal to percent is from\n",
    "# https://www.kite.com/python/answers/how-to-format-a-number-as-a-percentage-in-python\n",
    "print('Percent positive in the bean dataset is:\\n',\n",
    "      '{:.0%}'.format(bean_df_y.value_counts()[1]\n",
    "        /(bean_df_y.value_counts()[0]\n",
    "        + bean_df_y.value_counts()[1])))\n",
    "\n",
    "print('Percent positive in the bike dataset is:\\n',\n",
    "      '{:.0%}'.format(bike_df_y.value_counts()[1]\n",
    "        /(bike_df_y.value_counts()[0] + \n",
    "        bike_df_y.value_counts()[1])))\n",
    "\n",
    "print('Percent positive in the shoppers dataset is:\\n',\n",
    "      '{:.0%}'.format(shoppers_df_y.value_counts()[1]\n",
    "        /(shoppers_df_y.value_counts()[0] + \n",
    "        shoppers_df_y.value_counts()[1])))\n",
    "\n",
    "print('Percent positive in the stars dataset is:\\n',\n",
    "      '{:.0%}'.format(stars_df_y.value_counts()[1]\n",
    "        /(stars_df_y.value_counts()[0] + \n",
    "        stars_df_y.value_counts()[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_clf(data, trials):\n",
    "\n",
    "    # Initializing the lists that will hold the metric scores\n",
    "    # for each algorithm's train and test set\n",
    "    logreg_acc_scores_train = []\n",
    "    logreg_roc_auc_scores_train = []\n",
    "    logreg_f1_scores_train = []\n",
    "    logreg_acc_scores_test = []\n",
    "    logreg_roc_auc_scores_test = []\n",
    "    logreg_f1_scores_test = []\n",
    "    \n",
    "    for trial in range(trials):\n",
    "        \n",
    "        # Making the train-test split for each dataset\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data[0],\n",
    "                                                            data[1],\n",
    "                                                            train_size=5000)\n",
    "        split = [X_train, X_test, y_train, y_test]\n",
    "        # Pulling out the proper train/test splits out of the all_splits list\n",
    "        X_train = split[0]\n",
    "        X_test = split[1]\n",
    "        y_train = split[2]\n",
    "        y_test = split[3]\n",
    "\n",
    "        # Creating a pipeline with the classifier\n",
    "        # Pipeline isn't necessary - just reusing code from a previous version\n",
    "        pipe = Pipeline([('classifier', LogisticRegression())])\n",
    "\n",
    "\n",
    "        # Creating the C_values for the grid search;\n",
    "        # newton-cg with a C value of 10^-8 does not converge: this\n",
    "        # combination is not run to avoid warnings\n",
    "        C_values = [10**-8, 10**-7, 10**-6, 10**-5, 10**-4, 10**-3, 10**-2,\n",
    "                    10**-1, 10**0, 10**1, 10**2, 10**3, 10**4]\n",
    "\n",
    "        # Defining the search space\n",
    "        search_space = [{'classifier': [LogisticRegression(max_iter=10000)],\n",
    "                         'classifier__solver': ['saga'],\n",
    "                         'classifier__penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "                         'classifier__C': C_values},\n",
    "                        {'classifier': [LogisticRegression(max_iter=10000)],\n",
    "                         'classifier__solver': ['liblinear'],\n",
    "                         'classifier__penalty': ['l1', 'l2'],\n",
    "                         'classifier__C': C_values},\n",
    "                        {'classifier': [LogisticRegression(max_iter=10000)],\n",
    "                         'classifier__solver': ['newton-cg', 'lbfgs', 'sag'],\n",
    "                         'classifier__penalty': ['none', 'l2'],\n",
    "                         'classifier__C': C_values}]\n",
    "\n",
    "        # Defining parameters for the grid search\n",
    "        log_search = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                                  scoring=['accuracy', 'roc_auc', 'f1'], \n",
    "                                  refit='accuracy', n_jobs=-1)\n",
    "\n",
    "        # Fitting the search model to find the best parameters\n",
    "        log_model = log_search.fit(X_train, y_train)\n",
    "\n",
    "        # Setting up the classifier with the parameters with the best accuracy\n",
    "        acc_params = log_model.cv_results_['params'][np.argmin(log_model.cv_results_\n",
    "                                                            ['rank_test_accuracy'])]\n",
    "        \n",
    "        acc_pipe = pipe.set_params(**acc_params)\n",
    "        acc_pred = pipe.fit(X_train, y_train)\n",
    "        y_train_pred_acc = acc_pred.predict(X_train)\n",
    "        y_test_pred_acc = acc_pred.predict(X_test)\n",
    "\n",
    "        # Setting up the classifier with the parameters with the best roc\n",
    "        roc_auc_params = log_model.cv_results_['params'][np.argmin(log_model.cv_results_\n",
    "                                                                ['rank_test_roc_auc'])]\n",
    "       \n",
    "        roc_auc_pipe = pipe.set_params(**roc_auc_params)\n",
    "        roc_auc_pred = roc_auc_pipe.fit(X_train, y_train)\n",
    "        y_train_pred_roc_auc = roc_auc_pred.predict(X_train)\n",
    "        y_test_pred_roc_auc = roc_auc_pred.predict(X_test)\n",
    "\n",
    "        # Setting up the classifier with the parameters with the best f1\n",
    "        f1_params = log_model.cv_results_['params'][np.argmin(log_model.cv_results_\n",
    "                                                              ['rank_test_f1'])]\n",
    "            \n",
    "        f1_pipe = pipe.set_params(**f1_params)\n",
    "        f1_pred = f1_pipe.fit(X_train, y_train)\n",
    "        y_train_pred_f1 = f1_pred.predict(X_train)\n",
    "        y_test_pred_f1 = f1_pred.predict(X_test)\n",
    "\n",
    "        # Calculating and appending the logistic regression metrics to their respective\n",
    "        # lists\n",
    "        logreg_acc_scores_train.append(accuracy_score(y_train, y_train_pred_acc))\n",
    "        logreg_roc_auc_scores_train.append(roc_auc_score(y_train, y_train_pred_roc_auc))\n",
    "        logreg_f1_scores_train.append(f1_score(y_train, y_train_pred_f1))\n",
    "        logreg_acc_scores_test.append(accuracy_score(y_test, y_test_pred_acc))\n",
    "        logreg_roc_auc_scores_test.append(roc_auc_score(y_test, y_test_pred_roc_auc))\n",
    "        logreg_f1_scores_test.append(f1_score(y_test, y_test_pred_f1))\n",
    "\n",
    "    # Returning a list of the training metrics and testing metrics on the dataset\n",
    "    return ([logreg_acc_scores_train, logreg_roc_auc_scores_train,\n",
    "             logreg_f1_scores_train], [logreg_acc_scores_test, \n",
    "             logreg_roc_auc_scores_test, logreg_f1_scores_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def DT_clf(data, trials):\n",
    "    \n",
    "    # Initializing the lists that will hold the metric scores\n",
    "    # for each algorithm's train and test set\n",
    "    DT_acc_scores_train = []\n",
    "    DT_roc_auc_scores_train = []\n",
    "    DT_f1_scores_train = []\n",
    "    DT_acc_scores_test = []\n",
    "    DT_roc_auc_scores_test = []\n",
    "    DT_f1_scores_test = []\n",
    "    \n",
    "    for trial in range(trials):\n",
    "        \n",
    "        # Making the train-test split for each dataset\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data[0],\n",
    "                                                            data[1],\n",
    "                                                            train_size=5000)\n",
    "        split = [X_train, X_test, y_train, y_test]\n",
    "    \n",
    "        # Pulling out the proper train/test splits out of the all_splits list\n",
    "        X_train = split[0]\n",
    "        X_test = split[1]\n",
    "        y_train = split[2]\n",
    "        y_test = split[3]\n",
    "\n",
    "        # Creating a pipeline with the classifier\n",
    "        # Pipeline isn't needed - just reusing code from a previous version\n",
    "        pipe = Pipeline([('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "        # Defining the search space\n",
    "        search_space = [{'classifier': [DecisionTreeClassifier()],\n",
    "                         'classifier__criterion': ['gini', 'entropy'],\n",
    "                         'classifier__max_depth': list(range(1,21)),\n",
    "                         'classifier__ccp_alpha': list(range(1,21)),\n",
    "                         'classifier__class_weight': [{0:1,1:1},{0:2,1:1},\n",
    "                                                      {0:1,1:2},{0:5,1:1},\n",
    "                                                      {0:1,1:5},{0:5,1:2},\n",
    "                                                      {0:2,1:5},{0:5,1:2},\n",
    "                                                      {0:10,1:1},{0:1,1:10},\n",
    "                                                      {0:10,1:2},{0:2,1:10},\n",
    "                                                      {0:5,1:10},{0:10,1:5}]}]\n",
    "\n",
    "        # Defining parameters for the grid search\n",
    "        DT_search = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                                 scoring=['accuracy', 'roc_auc', 'f1'], \n",
    "                                 refit='accuracy', n_jobs=-1)\n",
    "\n",
    "        # Fitting the search model to find the best parameters\n",
    "        DT_model = DT_search.fit(X_train, y_train)\n",
    "\n",
    "        # Setting up the classifier with the parameters with the best accuracy score\n",
    "        acc_params = DT_model.cv_results_['params'][np.argmin(DT_model.cv_results_\n",
    "                                                            ['rank_test_accuracy'])]\n",
    "            \n",
    "        acc_pipe = pipe.set_params(**acc_params)\n",
    "        acc_pred = pipe.fit(X_train, y_train)\n",
    "        y_train_pred_acc = acc_pred.predict(X_train)\n",
    "        y_test_pred_acc = acc_pred.predict(X_test)\n",
    "\n",
    "        # Setting up the classifier with the parameters with the best roc score\n",
    "        roc_auc_params = DT_model.cv_results_['params'][np.argmin(DT_model.cv_results_\n",
    "                                                                ['rank_test_roc_auc'])]\n",
    "            \n",
    "        roc_auc_pipe = pipe.set_params(**roc_auc_params)\n",
    "        roc_auc_pred = roc_auc_pipe.fit(X_train, y_train)\n",
    "        y_train_pred_roc_auc = roc_auc_pred.predict(X_train)\n",
    "        y_test_pred_roc_auc = roc_auc_pred.predict(X_test)\n",
    "\n",
    "        # Setting up the classifier with the parameters with the best f1 score\n",
    "        f1_params = DT_model.cv_results_['params'][np.argmin(DT_model.cv_results_\n",
    "                                                            ['rank_test_f1'])]\n",
    "            \n",
    "        f1_pipe = pipe.set_params(**f1_params)\n",
    "        f1_pred = f1_pipe.fit(X_train, y_train)\n",
    "        y_train_pred_f1 = f1_pred.predict(X_train)\n",
    "        y_test_pred_f1 = f1_pred.predict(X_test)\n",
    "        \n",
    "        # Calculating and appending the DT metrics to their respective lists\n",
    "        DT_acc_scores_train.append(accuracy_score(y_train, y_train_pred_acc))\n",
    "        DT_roc_auc_scores_train.append(roc_auc_score(y_train, y_train_pred_roc_auc))\n",
    "        DT_f1_scores_train.append(f1_score(y_train, y_train_pred_f1))\n",
    "        DT_acc_scores_test.append(accuracy_score(y_test, y_test_pred_acc))\n",
    "        DT_roc_auc_scores_test.append(roc_auc_score(y_test, y_test_pred_roc_auc))\n",
    "        DT_f1_scores_test.append(f1_score(y_test, y_test_pred_f1))\n",
    "    \n",
    "    # Returning a list of the training metrics and testing metrics on the dataset\n",
    "    return ([DT_acc_scores_train, DT_roc_auc_scores_train,\n",
    "             DT_f1_scores_train], [DT_acc_scores_test, \n",
    "             DT_roc_auc_scores_test, DT_f1_scores_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_clf(data, trials):\n",
    "    \n",
    "    # Initializing the lists that will hold the metric scores\n",
    "    # for each algorithm's train and test set\n",
    "    RF_acc_scores_train = []\n",
    "    RF_roc_auc_scores_train = []\n",
    "    RF_f1_scores_train = []\n",
    "    RF_acc_scores_test = []\n",
    "    RF_roc_auc_scores_test = []\n",
    "    RF_f1_scores_test = []\n",
    "    \n",
    "    for trial in range(trials):\n",
    "        \n",
    "        # Making the train-test split for each dataset\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data[0],\n",
    "                                                            data[1],\n",
    "                                                            train_size=5000)\n",
    "        split = [X_train, X_test, y_train, y_test]\n",
    "    \n",
    "        # Pulling out the proper train/test splits out of the all_splits list\n",
    "        X_train = split[0]\n",
    "        X_test = split[1]\n",
    "        y_train = split[2]\n",
    "        y_test = split[3]\n",
    "\n",
    "        # Creating a pipeline with the classifier\n",
    "        # Pipeline isn't needed - just reusing code from a previous version\n",
    "        pipe = Pipeline([('classifier', RandomForestClassifier())])\n",
    "\n",
    "        # Defining the search space\n",
    "        search_space = [{'classifier__n_estimators': [1024],\n",
    "                         'classifier__criterion': ['gini', 'entropy'],\n",
    "                         'classifier__max_features': [1, 2, 4, 6, \n",
    "                                                     8, 12, 16, 20]}]\n",
    "\n",
    "        # Defining parameters for the grid search\n",
    "        RF_search = GridSearchCV(pipe, search_space, cv=StratifiedKFold(n_splits=5), \n",
    "                                 scoring=['accuracy', 'roc_auc', 'f1'], \n",
    "                                 refit='accuracy', n_jobs=-1)\n",
    "\n",
    "        # Fitting the search model to find the best parameters\n",
    "        RF_model = RF_search.fit(X_train, y_train)\n",
    "\n",
    "        # Setting up the classifier with the parameters with the best accuracy score\n",
    "        acc_params = RF_model.cv_results_['params'][np.argmin(RF_model.cv_results_\n",
    "                                                            ['rank_test_accuracy'])]\n",
    "            \n",
    "        acc_pipe = pipe.set_params(**acc_params)\n",
    "        acc_pred = pipe.fit(X_train, y_train)\n",
    "        y_train_pred_acc = acc_pred.predict(X_train)\n",
    "        y_test_pred_acc = acc_pred.predict(X_test)\n",
    "\n",
    "        # Setting up the classifier with the parameters with the best roc score\n",
    "        roc_auc_params = RF_model.cv_results_['params'][np.argmin(RF_model.cv_results_\n",
    "                                                                ['rank_test_roc_auc'])]\n",
    "            \n",
    "        roc_auc_pipe = pipe.set_params(**roc_auc_params)\n",
    "        roc_auc_pred = roc_auc_pipe.fit(X_train, y_train)\n",
    "        y_train_pred_roc_auc = roc_auc_pred.predict(X_train)\n",
    "        y_test_pred_roc_auc = roc_auc_pred.predict(X_test)\n",
    "\n",
    "        # Setting up the classifier with the parameters with the best f1 score\n",
    "        f1_params = RF_model.cv_results_['params'][np.argmin(RF_model.cv_results_\n",
    "                                                            ['rank_test_f1'])]\n",
    "            \n",
    "        f1_pipe = pipe.set_params(**f1_params)\n",
    "        f1_pred = f1_pipe.fit(X_train, y_train)\n",
    "        y_train_pred_f1 = f1_pred.predict(X_train)\n",
    "        y_test_pred_f1 = f1_pred.predict(X_test)\n",
    "        \n",
    "        # Calculating and appending the DT metrics to their respective lists\n",
    "        RF_acc_scores_train.append(accuracy_score(y_train, y_train_pred_acc))\n",
    "        RF_roc_auc_scores_train.append(roc_auc_score(y_train, y_train_pred_roc_auc))\n",
    "        RF_f1_scores_train.append(f1_score(y_train, y_train_pred_f1))\n",
    "        RF_acc_scores_test.append(accuracy_score(y_test, y_test_pred_acc))\n",
    "        RF_roc_auc_scores_test.append(roc_auc_score(y_test, y_test_pred_roc_auc))\n",
    "        RF_f1_scores_test.append(f1_score(y_test, y_test_pred_f1))\n",
    "    \n",
    "    # Returning a list of the training metrics and testing metrics on the dataset\n",
    "    return ([RF_acc_scores_train, RF_roc_auc_scores_train,\n",
    "             RF_f1_scores_train], [RF_acc_scores_test, \n",
    "             RF_roc_auc_scores_test, RF_f1_scores_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\npete\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initializing the lists that will hold the metric scores\n",
    "# for each algorithm's train and test set\n",
    "logreg_acc_train = []\n",
    "logreg_roc_auc_train = []\n",
    "logreg_f1_train = []\n",
    "logreg_acc_test = []\n",
    "logreg_roc_auc_test = []\n",
    "logreg_f1_test = []\n",
    "\n",
    "DT_acc_train = []\n",
    "DT_roc_auc_train = []\n",
    "DT_f1_train = []\n",
    "DT_acc_test = []\n",
    "DT_roc_auc_test = []\n",
    "DT_f1_test = []\n",
    "\n",
    "RF_acc_train = []\n",
    "RF_roc_auc_train = []\n",
    "RF_f1_train = []\n",
    "RF_acc_test = []\n",
    "RF_roc_auc_test = []\n",
    "RF_f1_test = []\n",
    "\n",
    "# Setting the number of trials to be run for each algorithm\n",
    "trials = 5\n",
    "\n",
    "# Looping over the datasets, running every algorithm on each\n",
    "for dat in data:\n",
    "    \n",
    "    # Initializing lists to hold the metric scores to be pulled out\n",
    "    # afterwards\n",
    "    logreg_scores_temp = []\n",
    "    DT_scores_temp = []\n",
    "    RF_scores_temp = []\n",
    "    \n",
    "    # Appending the logistic regression metrics to their respective lists\n",
    "    logreg_scores_temp.append(logreg_clf(dat, trials))\n",
    "    logreg_acc_train.append(logreg_scores_temp[0][0][0])\n",
    "    logreg_roc_auc_train.append(logreg_scores_temp[0][0][1])\n",
    "    logreg_f1_train.append(logreg_scores_temp[0][0][2])\n",
    "    logreg_acc_test.append(logreg_scores_temp[0][1][0])\n",
    "    logreg_roc_auc_test.append(logreg_scores_temp[0][1][1])\n",
    "    logreg_f1_test.append(logreg_scores_temp[0][1][2])\n",
    "    \n",
    "    # Appending the DT metrics to their respective lists\n",
    "    DT_scores_temp.append(DT_clf(dat, trials))\n",
    "    DT_acc_train.append(DT_scores_temp[0][0][0])\n",
    "    DT_roc_auc_train.append(DT_scores_temp[0][0][1])\n",
    "    DT_f1_train.append(DT_scores_temp[0][0][2])\n",
    "    DT_acc_test.append(DT_scores_temp[0][1][0])\n",
    "    DT_roc_auc_test.append(DT_scores_temp[0][1][1])\n",
    "    DT_f1_test.append(DT_scores_temp[0][1][2])\n",
    "    \n",
    "    # Appending the random forest metrics to their respective lists\n",
    "    RF_scores_temp.append(RF_clf(dat, trials))\n",
    "    RF_acc_train.append(RF_scores_temp[0][0][0])\n",
    "    RF_roc_auc_train.append(RF_scores_temp[0][0][1])\n",
    "    RF_f1_train.append(RF_scores_temp[0][0][2])\n",
    "    RF_acc_test.append(RF_scores_temp[0][1][0])\n",
    "    RF_roc_auc_test.append(RF_scores_temp[0][1][1])\n",
    "    RF_f1_test.append(RF_scores_temp[0][1][2])\n",
    "\n",
    "# Making a list to index through and get mean scores of the trials\n",
    "all_list = [logreg_acc_train, logreg_roc_auc_train,\n",
    "             logreg_f1_train, logreg_acc_test,\n",
    "             logreg_roc_auc_test, logreg_f1_test,\n",
    "             DT_acc_train, DT_roc_auc_train,\n",
    "             DT_f1_train, DT_acc_test,\n",
    "             DT_roc_auc_test, DT_f1_test,\n",
    "             RF_acc_train, RF_roc_auc_train,\n",
    "             RF_f1_train, RF_acc_test,\n",
    "             RF_roc_auc_test, RF_f1_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the list to hold the mean scores across trials\n",
    "mean_logreg_acc_train = []\n",
    "mean_logreg_roc_auc_train = []\n",
    "mean_logreg_f1_train = []\n",
    "mean_logreg_acc_test = []\n",
    "mean_logreg_roc_auc_test = []\n",
    "mean_logreg_f1_test = []\n",
    "\n",
    "mean_DT_acc_train = []\n",
    "mean_DT_roc_auc_train = []\n",
    "mean_DT_f1_train = []\n",
    "mean_DT_acc_test = []\n",
    "mean_DT_roc_auc_test = []\n",
    "mean_DT_f1_test = []\n",
    "\n",
    "mean_RF_acc_train = []\n",
    "mean_RF_roc_auc_train = []\n",
    "mean_RF_f1_train = []\n",
    "mean_RF_acc_test = []\n",
    "mean_RF_roc_auc_test = []\n",
    "mean_RF_f1_test = []\n",
    "\n",
    "# Idea for average function from\n",
    "# https://www.geeksforgeeks.org/find-average-list-python/\n",
    "def list_average(item):\n",
    "    \n",
    "    return sum(item)/len(item)\n",
    "\n",
    "# Calculating the mean of the scores on each dataset\n",
    "for num in range(4):    \n",
    "    \n",
    "    mean_logreg_acc_train.append(list_average(all_list[0][num]))\n",
    "    mean_logreg_roc_auc_train.append(list_average(all_list[1][num]))\n",
    "    mean_logreg_f1_train.append(list_average(all_list[2][num]))\n",
    "    mean_logreg_acc_test.append(list_average(all_list[3][num]))\n",
    "    mean_logreg_roc_auc_test.append(list_average(all_list[4][num]))\n",
    "    mean_logreg_f1_test.append(list_average(all_list[5][num]))\n",
    "\n",
    "    mean_DT_acc_train.append(list_average(all_list[6][num]))\n",
    "    mean_DT_roc_auc_train.append(list_average(all_list[7][num]))\n",
    "    mean_DT_f1_train.append(list_average(all_list[8][num]))\n",
    "    mean_DT_acc_test.append(list_average(all_list[9][num]))\n",
    "    mean_DT_roc_auc_test.append(list_average(all_list[10][num]))\n",
    "    mean_DT_f1_test.append(list_average(all_list[11][num]))\n",
    "\n",
    "    mean_RF_acc_train.append(list_average(all_list[12][num]))\n",
    "    mean_RF_roc_auc_train.append(list_average(all_list[13][num]))\n",
    "    mean_RF_f1_train.append(list_average(all_list[14][num]))\n",
    "    mean_RF_acc_test.append(list_average(all_list[15][num]))\n",
    "    mean_RF_roc_auc_test.append(list_average(all_list[16][num]))\n",
    "    mean_RF_f1_test.append(list_average(all_list[17][num]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9662382054863039, 0.6992271147682532, 0.5170741947842268, 0.8838737142205242]\n"
     ]
    }
   ],
   "source": [
    "# Averaging the metric data across datasets and putting them\n",
    "# into a list to be used in a dataframe\n",
    "avg_data_logreg_train = [list_average(mean_logreg_acc_train),\n",
    "                         list_average(mean_logreg_roc_auc_train),\n",
    "                         list_average(mean_logreg_f1_train)]\n",
    "avg_data_DT_train = [list_average(mean_DT_acc_train),\n",
    "                         list_average(mean_DT_roc_auc_train),\n",
    "                         list_average(mean_DT_f1_train)]\n",
    "avg_data_RF_train = [list_average(mean_RF_acc_train),\n",
    "                         list_average(mean_RF_roc_auc_train),\n",
    "                         list_average(mean_RF_f1_train)]\n",
    "\n",
    "avg_data_logreg_test = [list_average(mean_logreg_acc_test),\n",
    "                         list_average(mean_logreg_roc_auc_test),\n",
    "                         list_average(mean_logreg_f1_test)]\n",
    "avg_data_DT_test = [list_average(mean_DT_acc_test),\n",
    "                         list_average(mean_DT_roc_auc_test),\n",
    "                         list_average(mean_DT_f1_test)]\n",
    "avg_data_RF_test = [list_average(mean_RF_acc_test),\n",
    "                         list_average(mean_RF_roc_auc_test),\n",
    "                         list_average(mean_RF_f1_test)]\n",
    "\n",
    "# Averaging the dataset results across metrics and putting them\n",
    "# into a list to be used in a dataframe\n",
    "# Method used for performing element-wise computations\n",
    "# https://blog.finxter.com/how-to-average-a-list-of-lists-in-python/\n",
    "d = [mean_logreg_acc_train, mean_logreg_roc_auc_train, mean_logreg_f1_train]\n",
    "avg_metric_logreg_train = [sum(a)/len(a) for a in zip(*d)]\n",
    "d = [mean_DT_acc_train, mean_DT_roc_auc_train, mean_DT_f1_train]\n",
    "avg_metric_DT_train = [sum(a)/len(a) for a in zip(*d)]\n",
    "d = [mean_RF_acc_train, mean_RF_roc_auc_train, mean_RF_f1_train]\n",
    "avg_metric_RF_train = [sum(a)/len(a) for a in zip(*d)]\n",
    "\n",
    "d = [mean_logreg_acc_test, mean_logreg_roc_auc_test, mean_logreg_f1_test]\n",
    "avg_metric_logreg_test = [sum(a)/len(a) for a in zip(*d)]\n",
    "d = [mean_DT_acc_test, mean_DT_roc_auc_test, mean_DT_f1_test]\n",
    "avg_metric_DT_test = [sum(a)/len(a) for a in zip(*d)]\n",
    "d = [mean_RF_acc_test, mean_RF_roc_auc_test, mean_RF_f1_test]\n",
    "avg_metric_RF_test = [sum(a)/len(a) for a in zip(*d)]\n",
    "\n",
    "print(mean_logreg_roc_auc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic regression</th>\n",
       "      <th>Decision trees</th>\n",
       "      <th>Random forests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.826</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.767</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.717</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Logistic regression  Decision trees  Random forests\n",
       "acc                 0.914           0.826             1.0\n",
       "roc                 0.767           0.500             1.0\n",
       "f1                  0.717           0.362             1.0\n",
       "mean                0.799           0.563             1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a dataframe of the training algorithm/metric combinations\n",
    "df = pd.DataFrame([avg_data_logreg_train, avg_data_DT_train, avg_data_RF_train],\n",
    "                              index=['acc', 'roc', 'f1'],\n",
    "                              columns=['Logistic regression', 'Decision trees',\n",
    "                                       'Random forests'])\n",
    "\n",
    "df['Logistic regression'] = avg_data_logreg_train\n",
    "df['Decision trees'] = avg_data_DT_train\n",
    "df['Random forests'] = avg_data_RF_train\n",
    "df = df.append(df.mean().rename('mean')).round(3)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic regression</th>\n",
       "      <th>Decision trees</th>\n",
       "      <th>Random forests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.768</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.713</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Logistic regression  Decision trees  Random forests\n",
       "acc                 0.914           0.826           0.959\n",
       "roc                 0.768           0.500           0.878\n",
       "f1                  0.713           0.362           0.822\n",
       "mean                0.798           0.563           0.887"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a dataframe of the testing algorith/metric combinations\n",
    "df = pd.DataFrame([avg_data_logreg_test, avg_data_DT_test, avg_data_RF_test],\n",
    "                              index=['acc', 'roc', 'f1'],\n",
    "                              columns=['Logistic regression', 'Decision trees',\n",
    "                                       'Random forests'])\n",
    "\n",
    "df['Logistic regression'] = avg_data_logreg_test\n",
    "df['Decision trees'] = avg_data_DT_test\n",
    "df['Random forests'] = avg_data_RF_test\n",
    "df = df.append(df.mean().rename('mean')).round(3)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bean</th>\n",
       "      <th>bike</th>\n",
       "      <th>shoppers</th>\n",
       "      <th>stars</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.967</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision trees</th>\n",
       "      <td>0.537</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forests</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bean   bike  shoppers  stars   mean\n",
       "Logistic regression  0.967  0.804     0.512  0.913  0.799\n",
       "Decision trees       0.537  0.665     0.534  0.515  0.563\n",
       "Random forests       1.000  1.000     1.000  1.000  1.000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a dataframe of the training algorithm/dataset combinations\n",
    "df = pd.DataFrame([avg_metric_logreg_train,avg_metric_DT_train,avg_metric_RF_train],\n",
    "                              index=['Logistic regression', 'Decision trees',\n",
    "                                     'Random forests'],\n",
    "                              columns=['bean', 'bike', 'shoppers', 'stars'])\n",
    "df['mean'] = df.mean(axis=1)\n",
    "df = df.round(3)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bean</th>\n",
       "      <th>bike</th>\n",
       "      <th>shoppers</th>\n",
       "      <th>stars</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic regression</th>\n",
       "      <td>0.968</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision trees</th>\n",
       "      <td>0.537</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forests</th>\n",
       "      <td>0.964</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bean   bike  shoppers  stars   mean\n",
       "Logistic regression  0.968  0.805     0.504  0.916  0.798\n",
       "Decision trees       0.537  0.665     0.535  0.514  0.563\n",
       "Random forests       0.964  1.000     0.657  0.925  0.887"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a dataframe of the testing algorithm/dataset combinations\n",
    "df = pd.DataFrame([avg_metric_logreg_test,avg_metric_DT_test,avg_metric_RF_test],\n",
    "                              index=['Logistic regression', 'Decision trees',\n",
    "                                     'Random forests'],\n",
    "                              columns=['bean', 'bike', 'shoppers', 'stars'])\n",
    "df['mean'] = df.mean(axis=1)\n",
    "df = df.round(3)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 2 p-values:\n",
      "\n",
      "Testing p-value between logistic regression and random forest on the bean data:\n",
      " 0.45538329188490956\n",
      "\n",
      "Testing p-value between logistic regression and decision tree on the bean data:\n",
      " 3.510175484062577e-07\n",
      "\n",
      "Testing p-value between random forest and logistic regression on the bike data:\n",
      " 4.865508201408333e-10\n",
      "\n",
      "Testing p-value between random forest and decision tree on the bike data:\n",
      " 1.4735748423265126e-10\n",
      "\n",
      "Testing p-value between random forest and logistic regression on the shoppers data:\n",
      " 0.10618497386580875\n",
      "\n",
      "Testing p-value between random forest and decision tree on the shoppers data:\n",
      " 0.14423704773003818\n",
      "\n",
      "Testing p-value between random forest and logistic regression on the stars data:\n",
      " 0.6071199118028152\n",
      "\n",
      "Testing p-value between random forest and decision tree on the stars data:\n",
      " 5.023997542860683e-05\n",
      "\n",
      "Testing p-value between the mean of random forest and the mean of logistic regression:\n",
      " 0.011925362902675997\n",
      "\n",
      "Testing p-value between the mean of random forest and the mean of decision tree:\n",
      " 2.070430318949014e-08\n",
      "\n",
      "Table 3 p-values:\n",
      "\n",
      "p-value between random forest accuracy and logistic regression accuracy:\n",
      " 0.025338665696158186\n",
      "\n",
      "p-value between random forest accuracy and decision tree accuracy:\n",
      " 8.088042618093579e-07\n",
      "\n",
      "p-value between random forest ROC and logistic regression ROC:\n",
      " 0.04088869642196997\n",
      "\n",
      "p-value between random forest ROC and decision tree ROC:\n",
      " 6.45310312900364e-14\n",
      "\n",
      "p-value between random forest f1 and logistic regression f1:\n",
      " 0.24099802736925008\n",
      "\n",
      "p-value between random forest f1 and decision tree f1:\n",
      " 8.029655739740766e-07\n",
      "\n",
      "p-value between random forest mean and logistic regression mean:\n",
      " 0.020085076176803843\n",
      "\n",
      "p-value between random forest mean and decision tree mean:\n",
      " 1.9622899542885124e-13\n",
      "\n",
      "Table 4 p-values:\n",
      "\n",
      "Training p-value between random forest and logistic regression on the bean data:\n",
      " 5.072254235796008e-09\n",
      "\n",
      "Training p-value between logistic regression and decision tree on the bean data:\n",
      " 3.304153221587041e-07\n",
      "\n",
      "Training p-value between random forest and logistic regression on the bike data:\n",
      " 3.6813781222203227e-10\n",
      "\n",
      "Training p-value between random forest and decision tree on the bike data:\n",
      " 1.4090894669634575e-10\n",
      "\n",
      "Training p-value between random forest and logistic regression on the shoppers data:\n",
      " 8.62269320913401e-07\n",
      "\n",
      "Training p-value between random forest and decision tree on the shoppers data:\n",
      " 2.2219416009277352e-07\n",
      "\n",
      "Training p-value between random forest and logistic regression on the stars data:\n",
      " 5.739553023371645e-07\n",
      "\n",
      "Training p-value between random forest and decision tree on the stars data:\n",
      " 3.993081418601563e-06\n",
      "\n",
      "Training p-value between the mean of random forest and the mean of logistic regression:\n",
      " 5.355705722750554e-10\n",
      "\n",
      "Training p-value between the mean of random forest and the mean of decision tree:\n",
      " 1.8831036552581798e-18\n"
     ]
    }
   ],
   "source": [
    "# Finding the p-values between algorithm metrics\n",
    "# Method of combining lists inide a list from\n",
    "# https://stackoverflow.com/questions/952914/\n",
    "# how-to-make-a-flat-list-out-of-list-of-lists?rq=1\n",
    "\n",
    "print('\\nTable 2 p-values:')\n",
    "\n",
    "print('\\nTesting p-value between logistic regression and random forest on the bean data:\\n',\n",
    "     ttest_ind(logreg_acc_test[0] + logreg_roc_auc_test[0] + logreg_f1_test[0],\n",
    "              RF_acc_test[0] + RF_roc_auc_test[0] + RF_f1_test[0])[1])\n",
    "\n",
    "print('\\nTesting p-value between logistic regression and decision tree on the bean data:\\n',\n",
    "     ttest_ind(logreg_acc_test[0] + logreg_roc_auc_test[0] + logreg_f1_test[0],\n",
    "              DT_acc_test[0] + DT_roc_auc_test[0] + DT_f1_test[0])[1])\n",
    "\n",
    "print('\\nTesting p-value between random forest and logistic regression on the bike data:\\n',\n",
    "     ttest_ind(RF_acc_test[1] + RF_roc_auc_test[1] + RF_f1_test[1],\n",
    "              logreg_acc_test[1] + logreg_roc_auc_test[1] + logreg_f1_test[1])[1])\n",
    "\n",
    "print('\\nTesting p-value between random forest and decision tree on the bike data:\\n',\n",
    "     ttest_ind(RF_acc_test[1] + RF_roc_auc_test[1] + RF_f1_test[1],\n",
    "              DT_acc_test[1] + DT_roc_auc_test[1] + DT_f1_test[1])[1])\n",
    "\n",
    "print('\\nTesting p-value between random forest and logistic regression on the shoppers data:\\n',\n",
    "     ttest_ind(RF_acc_test[2] + RF_roc_auc_test[2] + RF_f1_test[2],\n",
    "              logreg_acc_test[2] + logreg_roc_auc_test[2] + logreg_f1_test[2])[1])\n",
    "\n",
    "print('\\nTesting p-value between random forest and decision tree on the shoppers data:\\n',\n",
    "     ttest_ind(RF_acc_test[2] + RF_roc_auc_test[2] + RF_f1_test[2],\n",
    "              DT_acc_test[2] + DT_roc_auc_test[2] + DT_f1_test[2])[1])\n",
    "\n",
    "print('\\nTesting p-value between random forest and logistic regression on the stars data:\\n',\n",
    "     ttest_ind(RF_acc_test[3] + RF_roc_auc_test[3] + RF_f1_test[3],\n",
    "              logreg_acc_test[3] + logreg_roc_auc_test[3] + logreg_f1_test[3])[1])\n",
    "\n",
    "print('\\nTesting p-value between random forest and decision tree on the stars data:\\n',\n",
    "     ttest_ind(RF_acc_test[3] + RF_roc_auc_test[3] + RF_f1_test[3],\n",
    "              DT_acc_test[3] + DT_roc_auc_test[3] + DT_f1_test[3])[1])\n",
    "\n",
    "print('\\nTesting p-value between the mean of random forest and the mean of logistic regression:\\n',\n",
    "      ttest_ind(RF_acc_test[1] + RF_roc_auc_test[1] + RF_f1_test[1]\n",
    "               + RF_acc_test[2] + RF_roc_auc_test[2] + RF_f1_test[2]\n",
    "               + RF_acc_test[3] + RF_roc_auc_test[3] + RF_f1_test[3],\n",
    "               logreg_acc_test[1] + logreg_roc_auc_test[1] + logreg_f1_test[1]\n",
    "               + logreg_acc_test[2] + logreg_roc_auc_test[2] + logreg_f1_test[2]\n",
    "               + logreg_acc_test[3] + logreg_roc_auc_test[3] + logreg_f1_test[3])[1])\n",
    "\n",
    "print('\\nTesting p-value between the mean of random forest and the mean of decision tree:\\n',\n",
    "      ttest_ind(RF_acc_test[1] + RF_roc_auc_test[1] + RF_f1_test[1]\n",
    "               + RF_acc_test[2] + RF_roc_auc_test[2] + RF_f1_test[2]\n",
    "               + RF_acc_test[3] + RF_roc_auc_test[3] + RF_f1_test[3],\n",
    "               DT_acc_test[1] + DT_roc_auc_test[1] + DT_f1_test[1]\n",
    "               + DT_acc_test[2] + DT_roc_auc_test[2] + DT_f1_test[2]\n",
    "               + DT_acc_test[3] + DT_roc_auc_test[3] + DT_f1_test[3])[1])\n",
    "\n",
    "print('\\nTable 3 p-values:\\n')\n",
    "\n",
    "print('p-value between random forest accuracy and logistic regression accuracy:\\n',\n",
    "      ttest_ind(list(itertools.chain(*RF_acc_test)),\n",
    "          list(itertools.chain(*logreg_acc_test)))[1])\n",
    "\n",
    "print('\\np-value between random forest accuracy and decision tree accuracy:\\n',\n",
    "      ttest_ind(list(itertools.chain(*RF_acc_test)),\n",
    "          list(itertools.chain(*DT_acc_test)))[1])\n",
    "\n",
    "print('\\np-value between random forest ROC and logistic regression ROC:\\n',\n",
    "      ttest_ind(list(itertools.chain(*RF_roc_auc_test)),\n",
    "          list(itertools.chain(*logreg_roc_auc_test)))[1])\n",
    "\n",
    "print('\\np-value between random forest ROC and decision tree ROC:\\n',\n",
    "      ttest_ind(list(itertools.chain(*RF_roc_auc_test)),\n",
    "          list(itertools.chain(*DT_roc_auc_test)))[1])\n",
    "\n",
    "print('\\np-value between random forest f1 and logistic regression f1:\\n',\n",
    "      ttest_ind(list(itertools.chain(*RF_f1_test)),\n",
    "          list(itertools.chain(*logreg_f1_test)))[1])\n",
    "\n",
    "print('\\np-value between random forest f1 and decision tree f1:\\n',\n",
    "      ttest_ind(list(itertools.chain(*RF_f1_test)),\n",
    "          list(itertools.chain(*DT_f1_test)))[1])\n",
    "\n",
    "print('\\np-value between random forest mean and logistic regression mean:\\n',\n",
    "      ttest_ind(list(itertools.chain(*RF_acc_test))\n",
    "     + list(itertools.chain(*RF_roc_auc_test))\n",
    "     + list(itertools.chain(*RF_f1_test)), list(itertools.chain(*logreg_acc_test))\n",
    "     + list(itertools.chain(*logreg_roc_auc_test))\n",
    "     + list(itertools.chain(*logreg_f1_test)))[1])\n",
    "\n",
    "print('\\np-value between random forest mean and decision tree mean:\\n',\n",
    "      ttest_ind(list(itertools.chain(*RF_acc_test))\n",
    "      + list(itertools.chain(*RF_roc_auc_test))\n",
    "     + list(itertools.chain(*RF_f1_test)), list(itertools.chain(*DT_acc_test))\n",
    "     + list(itertools.chain(*DT_roc_auc_test))\n",
    "     + list(itertools.chain(*DT_f1_test)))[1])\n",
    "\n",
    "print('\\nTable 4 p-values:')\n",
    "\n",
    "print('\\nTraining p-value between random forest and logistic regression on the bean data:\\n',\n",
    "     ttest_ind(RF_acc_train[0] + RF_roc_auc_train[0] + RF_f1_train[0],\n",
    "              logreg_acc_train[0] + logreg_roc_auc_train[0] + logreg_f1_train[0])[1])\n",
    "\n",
    "print('\\nTraining p-value between logistic regression and decision tree on the bean data:\\n',\n",
    "     ttest_ind(logreg_acc_test[0] + logreg_roc_auc_test[0] + logreg_f1_test[0],\n",
    "              DT_acc_train[0] + DT_roc_auc_train[0] + DT_f1_train[0])[1])\n",
    "\n",
    "print('\\nTraining p-value between random forest and logistic regression on the bike data:\\n',\n",
    "     ttest_ind(RF_acc_train[1] + RF_roc_auc_train[1] + RF_f1_train[1],\n",
    "              logreg_acc_train[1] + logreg_roc_auc_train[1] + logreg_f1_train[1])[1])\n",
    "\n",
    "print('\\nTraining p-value between random forest and decision tree on the bike data:\\n',\n",
    "     ttest_ind(RF_acc_train[1] + RF_roc_auc_train[1] + RF_f1_train[1],\n",
    "              DT_acc_train[1] + DT_roc_auc_train[1] + DT_f1_train[1])[1])\n",
    "\n",
    "print('\\nTraining p-value between random forest and logistic regression on the shoppers data:\\n',\n",
    "     ttest_ind(RF_acc_train[2] + RF_roc_auc_train[2] + RF_f1_train[2],\n",
    "              logreg_acc_train[2] + logreg_roc_auc_train[2] + logreg_f1_train[2])[1])\n",
    "\n",
    "print('\\nTraining p-value between random forest and decision tree on the shoppers data:\\n',\n",
    "     ttest_ind(RF_acc_train[2] + RF_roc_auc_train[2] + RF_f1_train[2],\n",
    "              DT_acc_train[2] + DT_roc_auc_train[2] + DT_f1_train[2])[1])\n",
    "\n",
    "print('\\nTraining p-value between random forest and logistic regression on the stars data:\\n',\n",
    "     ttest_ind(RF_acc_train[3] + RF_roc_auc_train[3] + RF_f1_train[3],\n",
    "              logreg_acc_train[3] + logreg_roc_auc_train[3] + logreg_f1_train[3])[1])\n",
    "\n",
    "print('\\nTraining p-value between random forest and decision tree on the stars data:\\n',\n",
    "     ttest_ind(RF_acc_train[3] + RF_roc_auc_train[3] + RF_f1_train[3],\n",
    "              DT_acc_train[3] + DT_roc_auc_train[3] + DT_f1_train[3])[1])\n",
    "\n",
    "print('\\nTraining p-value between the mean of random forest and the mean of logistic regression:\\n',\n",
    "      ttest_ind(RF_acc_train[1] + RF_roc_auc_train[1] + RF_f1_train[1]\n",
    "               + RF_acc_train[2] + RF_roc_auc_train[2] + RF_f1_train[2]\n",
    "               + RF_acc_train[3] + RF_roc_auc_train[3] + RF_f1_train[3],\n",
    "               logreg_acc_train[1] + logreg_roc_auc_train[1] + logreg_f1_train[1]\n",
    "               + logreg_acc_train[2] + logreg_roc_auc_train[2] + logreg_f1_train[2]\n",
    "               + logreg_acc_train[3] + logreg_roc_auc_train[3] + logreg_f1_train[3])[1])\n",
    "\n",
    "print('\\nTraining p-value between the mean of random forest and the mean of decision tree:\\n',\n",
    "      ttest_ind(RF_acc_train[1] + RF_roc_auc_train[1] + RF_f1_train[1]\n",
    "               + RF_acc_train[2] + RF_roc_auc_train[2] + RF_f1_train[2]\n",
    "               + RF_acc_train[3] + RF_roc_auc_train[3] + RF_f1_train[3],\n",
    "               DT_acc_train[1] + DT_roc_auc_train[1] + DT_f1_train[1]\n",
    "               + DT_acc_train[2] + DT_roc_auc_train[2] + DT_f1_train[2]\n",
    "               + DT_acc_train[3] + DT_roc_auc_train[3] + DT_f1_train[3])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
